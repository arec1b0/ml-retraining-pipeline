---
alwaysApply: true
---
# Configuration Management and Deployment Rules

## Configuration Architecture

### Configuration Management Standards
- Use **Hydra** or **dynaconf** for hierarchical configuration management
- Implement **environment-specific configurations** (dev, staging, prod)
- Use **YAML** format for human-readable configurations
- Implement **configuration validation** with Pydantic schemas
- Support **configuration inheritance** and **composition**

### Configuration Structure
```yaml
# configs/config.yaml
defaults:
  - data: default
  - model: random_forest
  - training: default
  - deployment: local
  - _self_

# Environment-specific overrides
environment: ${oc.env:ENVIRONMENT,dev}

# MLflow configuration
mlflow:
  tracking_uri: ${oc.env:MLFLOW_TRACKING_URI,"sqlite:///mlruns.db"}
  experiment_name: ${project.name}_${environment}
  artifact_location: ${oc.env:MLFLOW_ARTIFACT_ROOT,"./mlruns"}

# Logging configuration
logging:
  level: ${oc.env:LOG_LEVEL,INFO}
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    - console
    - file

# Resource configuration
resources:
  cpu_limit: ${oc.env:CPU_LIMIT,2}
  memory_limit: ${oc.env:MEMORY_LIMIT,"4Gi"}
  gpu_enabled: ${oc.env:GPU_ENABLED,false}
```

### Configuration Validation
```python
from pydantic import BaseModel, Field, validator
from typing import Optional, Dict, Any
from enum import Enum

class Environment(str, Enum):
    DEV = "dev"
    STAGING = "staging" 
    PROD = "prod"

class MLflowConfig(BaseModel):
    tracking_uri: str = Field(..., description="MLflow tracking URI")
    experiment_name: str = Field(..., description="Experiment name")
    artifact_location: Optional[str] = Field(None, description="Artifact storage location")

class ResourceConfig(BaseModel):
    cpu_limit: int = Field(2, ge=1, le=16)
    memory_limit: str = Field("4Gi", regex=r'^\d+[GMK]i?$')
    gpu_enabled: bool = Field(False)

class AppConfig(BaseModel):
    environment: Environment
    mlflow: MLflowConfig
    resources: ResourceConfig
    
    @validator('mlflow')
    def validate_mlflow_config(cls, v, values):
        if values.get('environment') == Environment.PROD:
            assert v.tracking_uri != "sqlite:///mlruns.db", \
                "SQLite not allowed in production"
        return v
```

## Container and Orchestration

### Docker Best Practices
```dockerfile
# Dockerfile
FROM python:3.11-slim as base

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Create non-root user
RUN groupadd -r mlops && useradd -r -g mlops mlops

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Set work directory
WORKDIR /app

# Copy and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY --chown=mlops:mlops . .

# Switch to non-root user
USER mlops

# Multi-stage build for production
FROM base as production
EXPOSE 8000
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Development stage with additional tools
FROM base as development
RUN pip install --no-cache-dir pytest black ruff
CMD ["python", "-m", "pytest"]
```

### Docker Compose for Local Development
```yaml
# docker-compose.yml
version: '3.8'

services:
  mlops-api:
    build:
      context: .
      target: development
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=dev
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/mlops
    volumes:
      - .:/app
      - model_artifacts:/app/artifacts
    depends_on:
      - postgres
      - mlflow

  mlflow:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://postgres:password@postgres:5432/mlflow
      - MLFLOW_ARTIFACTS_DESTINATION=/mlflow/artifacts
    volumes:
      - mlflow_artifacts:/mlflow/artifacts
    command: >
      bash -c "pip install mlflow[extras] psycopg2-binary &&
               mlflow server --host 0.0.0.0 --port 5000 
               --backend-store-uri $$MLFLOW_BACKEND_STORE_URI 
               --default-artifact-root $$MLFLOW_ARTIFACTS_DESTINATION"
    depends_on:
      - postgres

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=mlops
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
  mlflow_artifacts:
  model_artifacts:
```

## API Development and Serving

### FastAPI Model Serving
```python
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import mlflow.pyfunc
from typing import List, Dict, Any
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="MLOps Model API",
    description="Production ML model serving API",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class PredictionRequest(BaseModel):
    """Request schema for model predictions."""
    features: List[float] = Field(..., description="Input features")
    model_version: str = Field("latest", description="Model version to use")

class PredictionResponse(BaseModel):
    """Response schema for model predictions."""
    prediction: float = Field(..., description="Model prediction")
    confidence: float = Field(..., description="Prediction confidence")
    model_version: str = Field(..., description="Model version used")

class ModelManager:
    """Manage model loading and caching."""
    
    def __init__(self):
        self.models = {}
        self.load_models()
    
    def load_models(self):
        """Load models from MLflow registry."""
        try:
            model = mlflow.pyfunc.load_model(
                model_uri="models:/customer_churn_model/Production"
            )
            self.models["latest"] = model
            logger.info("Models loaded successfully")
        except Exception as e:
            logger.error(f"Failed to load models: {e}")
            raise

    def get_model(self, version: str = "latest"):
        """Get model by version."""
        if version not in self.models:
            raise HTTPException(status_code=404, detail=f"Model version {version} not found")
        return self.models[version]

model_manager = ModelManager()

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "models_loaded": len(model_manager.models)}

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """Make predictions using loaded model."""
    try:
        model = model_manager.get_model(request.model_version)
        
        # Make prediction
        prediction = model.predict([request.features])[0]
        
        # Calculate confidence (example implementation)
        confidence = min(abs(prediction), 1.0)
        
        return PredictionResponse(
            prediction=float(prediction),
            confidence=confidence,
            model_version=request.model_version
        )
    
    except Exception as e:
        logger.error(f"Prediction failed: {e}")
        raise HTTPException(status_code=500, detail="Prediction failed")

@app.get("/models")
async def list_models():
    """List available models."""
    return {"models": list(model_manager.models.keys())}
```

### Model Deployment Strategies

#### Blue-Green Deployment
```python
from kubernetes import client, config
from typing import Dict

class BlueGreenDeployer:
    """Implement blue-green deployment for ML models."""
    
    def __init__(self, namespace: str = "default"):
        config.load_incluster_config()  # or load_kube_config() for local
        self.k8s_apps = client.AppsV1Api()
        self.k8s_core = client.CoreV1Api()
        self.namespace = namespace
    
    def deploy_new_version(self, model_name: str, model_version: str):
        """Deploy new model version to green environment."""
        # Update green deployment with new model version
        deployment = self.k8s_apps.read_namespaced_deployment(
            name=f"{model_name}-green",
            namespace=self.namespace
        )
        
        # Update image tag or environment variable
        deployment.spec.template.spec.containers[0].env = [
            {"name": "MODEL_VERSION", "value": model_version}
        ]
        
        self.k8s_apps.patch_namespaced_deployment(
            name=f"{model_name}-green",
            namespace=self.namespace,
            body=deployment
        )
    
    def switch_traffic(self, model_name: str):
        """Switch traffic from blue to green."""
        service = self.k8s_core.read_namespaced_service(
            name=f"{model_name}-service",
            namespace=self.namespace
        )
        
        # Switch selector from blue to green
        current_color = service.spec.selector.get("version", "blue")
        new_color = "green" if current_color == "blue" else "blue"
        service.spec.selector["version"] = new_color
        
        self.k8s_core.patch_namespaced_service(
            name=f"{model_name}-service",
            namespace=self.namespace,
            body=service
        )
```

## Infrastructure as Code

### Kubernetes Manifests
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlops-model-api
  labels:
    app: mlops-model-api
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mlops-model-api
      version: blue
  template:
    metadata:
      labels:
        app: mlops-model-api
        version: blue
    spec:
      containers:
      - name: api
        image: mlops-model-api:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          value: "prod"
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            secretKeyRef:
              name: mlflow-secrets
              key: tracking-uri
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: mlops-model-api-service
spec:
  selector:
    app: mlops-model-api
    version: blue
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```

### Terraform Configuration
```hcl
# terraform/main.tf
provider "kubernetes" {
  config_path = "~/.kube/config"
}

resource "kubernetes_namespace" "mlops" {
  metadata {
    name = "mlops"
  }
}

resource "kubernetes_secret" "mlflow_secrets" {
  metadata {
    name      = "mlflow-secrets"
    namespace = kubernetes_namespace.mlops.metadata[0].name
  }

  data = {
    tracking-uri = var.mlflow_tracking_uri
  }

  type = "Opaque"
}

resource "kubernetes_config_map" "model_config" {
  metadata {
    name      = "model-config"
    namespace = kubernetes_namespace.mlops.metadata[0].name
  }

  data = {
    "config.yaml" = file("${path.module}/configs/prod.yaml")
  }
}
```

## CI/CD Integration

### GitHub Actions Workflow
```yaml
# .github/workflows/mlops-cd.yml
name: MLOps CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest black ruff
    
    - name: Lint code
      run: |
        black --check .
        ruff check .
    
    - name: Run tests
      run: pytest tests/ -v --cov=src
    
    - name: Data validation
      run: python -m src.data.validate

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build Docker image
      run: |
        docker build -t $REGISTRY/$IMAGE_NAME:$GITHUB_SHA .
        docker build -t $REGISTRY/$IMAGE_NAME:latest .
    
    - name: Push to registry
      run: |
        echo ${{ secrets.GITHUB_TOKEN }} | docker login $REGISTRY -u ${{ github.actor }} --password-stdin
        docker push $REGISTRY/$IMAGE_NAME:$GITHUB_SHA
        docker push $REGISTRY/$IMAGE_NAME:latest
    
    - name: Deploy to staging
      run: |
        kubectl set image deployment/mlops-model-api api=$REGISTRY/$IMAGE_NAME:$GITHUB_SHA -n staging
        kubectl rollout status deployment/mlops-model-api -n staging
```

## Security and Secrets Management

### Secret Management Patterns
```python
import os
from typing import Optional
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient

class SecretManager:
    """Manage secrets from various sources."""
    
    def __init__(self):
        self.vault_url = os.getenv("AZURE_KEY_VAULT_URL")
        if self.vault_url:
            credential = DefaultAzureCredential()
            self.secret_client = SecretClient(vault_url=self.vault_url, credential=credential)
    
    def get_secret(self, secret_name: str) -> Optional[str]:
        """Get secret from environment variable or Key Vault."""
        # First try environment variable
        secret = os.getenv(secret_name.upper())
        if secret:
            return secret
        
        # Fall back to Key Vault if configured
        if hasattr(self, 'secret_client'):
            try:
                secret = self.secret_client.get_secret(secret_name)
                return secret.value
            except Exception as e:
                logger.warning(f"Failed to retrieve secret {secret_name}: {e}")
        
        return None
```

## Anti-Patterns to Avoid

### Configuration and Deployment Anti-Patterns
- ❌ Don't hardcode **secrets or credentials** in configuration files
- ❌ Avoid **environment-specific code** instead of configuration
- ❌ Don't deploy without **proper health checks** and **monitoring**
- ❌ Avoid **single points of failure** in deployment architecture
- ❌ Don't skip **resource limits** in container orchestration
- ❌ Avoid **manual deployment processes** for production
- ❌ Don't ignore **security scanning** for container images
- ❌ Avoid **shared mutable state** in multi-instance deployments