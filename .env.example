# -----------------------------------------------------------------
# PROJECT CONFIGURATION
# -----------------------------------------------------------------
# Defines the name for various services (e.g., Prefect, MLflow)
PROJECT_NAME="AutomatedModelRetrainingPipeline"

# -----------------------------------------------------------------
# MLFLOW CONFIGURATION
# -----------------------------------------------------------------
# MLflow experiment tracking URI.
# For local development, this is a path to a local directory.
# For production, this would be a remote server URI (e.g., http://mlflow.example.com)
MLFLOW_TRACKING_URI="mlruns"

# The name of the experiment to log runs under.
MLFLOW_EXPERIMENT_NAME="SentimentModelRetraining"

# The name used in the MLflow Model Registry.
MODEL_REGISTRY_NAME="prod-sentiment-classifier"

# -----------------------------------------------------------------
# DATA & REPORTING PATHS
# -----------------------------------------------------------------
# These paths are relative to the project root.
RAW_DATA_PATH="data/raw/feedback.csv"
PROCESSED_DATA_PATH="data/processed/sentiment.csv"
REFERENCE_DATA_PATH="data/reference/sentiment_reference.csv"
EVIDENTLY_REPORTS_PATH="reports/evidently"

# -----------------------------------------------------------------
# MODEL TRAINING & VALIDATION THRESHOLDS
# -----------------------------------------------------------------
# Minimum accuracy required on the test set for a model
# to be considered "valid" for registration.
MIN_TRAINING_ACCURACY=0.75

# Threshold for the F1 score data drift test in Evidently.
# If the F1 score of the drift classifier is below this, no drift is detected.
DATA_DRIFT_F1_THRESHOLD=0.5

# Threshold for model performance drop.
# If the new model's accuracy is this much worse than the reference,
# it's considered degraded. (e.g., 0.05 = 5% drop)
MODEL_PERFORMANCE_DEGRADATION_THRESHOLD=0.05